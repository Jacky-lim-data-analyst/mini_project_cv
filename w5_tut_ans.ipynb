{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fad99a8d-a428-4e1e-964d-465d223fbf4d",
   "metadata": {},
   "source": [
    "# Weekly activity\n",
    "1. Rotate image by 45 degrees without cropping the sides of the image. (Hint: There are 2 strategies to tackle these problems). Use _\"lena.jfif\"_ as the input image.\n",
    "    - Use external libraries `imutils`.  \n",
    "    - Modify the transformation matrix.\n",
    "2. Use the images with titles: _\"flower.jfif\"_ and _\"native-bee.png\"_. I want to put flower above an image. If I add two images, it will change color. If I blend it, I get a transparent effect. But I want it to be opaque. If it was a rectangular region, we could use the ROI as we did in the previous section. But flower is not a rectangular region. This is where bitwise operations, like AND, OR, NOT and XOR really come in handy. The associated functions are `cv.bitwise_and()`, `cv.bitwise_or()` and `cv.bitwise_not()`. You need to use `cv.threshold` function to segment the flower. Please refer to [online documentation](https://docs.opencv.org/4.x/d0/d86/tutorial_py_image_arithmetics.html) for more info. The result should resemble the following:  \n",
    "![bee and flowers](img_embed/activity3.PNG \"bee_flower\")\n",
    "3. Write a function that randomly crop the central region of an image. The method signature should be as shown in the following:\n",
    "```\n",
    "random_center_crop(image, min_crop_ratio, max_crop_ratio)\n",
    "```\n",
    "\n",
    "4. Aside from Gaussian noise, name another common type of noise. Write the code to demonstrate how the noise can be included in an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed92ded5-7948-40f1-9160-5a6ae013247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup\n",
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24246012-4a04-4178-bc7b-6390310c242d",
   "metadata": {},
   "source": [
    "# Sample solution\n",
    "\n",
    "# Question 1\n",
    "## First way: using external package: `imutils`\n",
    "Remember to `pip install imutils`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c12067ff-a099-446a-afad-85a94729cdc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting imutils\n",
      "  Downloading imutils-0.5.4.tar.gz (17 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Building wheels for collected packages: imutils\n",
      "  Building wheel for imutils (pyproject.toml): started\n",
      "  Building wheel for imutils (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for imutils: filename=imutils-0.5.4-py3-none-any.whl size=25855 sha256=ff886d3f8775f20b9a8bb864d69dc4e09923fcbdc40f371a2ced265eb97f7a2b\n",
      "  Stored in directory: c:\\users\\user\\appdata\\local\\pip\\cache\\wheels\\5b\\76\\96\\ad0c321506837bef578cf3008df3916c23018435a355d9f6b1\n",
      "Successfully built imutils\n",
      "Installing collected packages: imutils\n",
      "Successfully installed imutils-0.5.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4469cb43-8c69-49aa-95ea-10c013eb672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1\n",
    "#1st way: Utilize external library\n",
    "from imutils import rotate_bound\n",
    "img = cv.imread('images/lena.jfif')\n",
    "rotated = rotate_bound(img, -45)\n",
    "\n",
    "cv.imshow('rotate', rotated)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b8ca86-b56c-433f-89aa-59d03d41f6fe",
   "metadata": {},
   "source": [
    "## 2nd way: modify the transformation matrix, M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9ea3899-1486-4d6d-a17c-b0face15c423",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd way: Modify the transformation matrix\n",
    "# define a custom function\n",
    "def rotate_image(img, angle, scale):\n",
    "    \"\"\"Arguments:\n",
    "    img: source image\n",
    "    angle, scale: argument for cv.getRotationMatrix2D\n",
    "    \"\"\"\n",
    "    height, width = img.shape[:2]\n",
    "    img_center = (int(width/2), int(height/2))\n",
    "    rotation_mat = cv.getRotationMatrix2D(img_center, angle, scale)\n",
    "    # result: 2x3 matrix\n",
    "    abs_cos = abs(rotation_mat[0, 0])\n",
    "    abs_sin = abs(rotation_mat[1, 0])\n",
    "    \n",
    "    new_w = int(abs_sin*height + abs_cos*width)\n",
    "    new_h = int(abs_cos*height + abs_sin*width)\n",
    "    \n",
    "    rotation_mat[0, 2] += new_w/2 - img_center[0]\n",
    "    rotation_mat[1, 2] += new_h/2 - img_center[1]\n",
    "    \n",
    "    rotated_img = cv.warpAffine(img, rotation_mat, (new_w, new_h))\n",
    "    return rotated_img\n",
    "\n",
    "rotate_img = rotate_image(img, 45, 1)\n",
    "\n",
    "cv.imshow('original', img)\n",
    "cv.imshow('rotate', rotate_img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21421e6b-4f85-4c20-9880-a33adcd22794",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3c81340-ed1a-4c9c-a604-2e3703dacbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv.imread('images/native-bee.png')\n",
    "img2 = cv.imread('images/flower.jfif')\n",
    "\n",
    "# Add flower on the top left hand corner of the bee image\n",
    "rows, cols = img2.shape[:2]\n",
    "roi = img1[:rows, :cols]\n",
    "\n",
    "# roi is the background; now we need to get the flower\n",
    "# Lets use image thresholding\n",
    "img2_gray = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n",
    "ret, mask = cv.threshold(img2_gray, 70, 255, cv.THRESH_BINARY)\n",
    "mask_inv = cv.bitwise_not(mask)\n",
    "\n",
    "# get the background (from img1) and foreground (flower from img2)\n",
    "img1_bg = cv.bitwise_and(roi, roi, mask=mask_inv)\n",
    "img2_fg = cv.bitwise_and(img2, img2, mask=mask)\n",
    "\n",
    "res = cv.add(img1_bg, img2_fg)\n",
    "img1[:rows, :cols] = res\n",
    "\n",
    "cv.imshow(\"flower_bee\", img1)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c3c695-dd65-4fae-9d63-46a956faf2b5",
   "metadata": {},
   "source": [
    "## Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "269802ad-95a4-4626-a3c4-7639a0f9c687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_center_crop(image, min_crop_ratio=0.5, max_crop_ratio=0.9):\n",
    "    height, width = image.shape[:2]\n",
    "\n",
    "    # randomly choos crop size\n",
    "    crop_ratio = random.uniform(min_crop_ratio, max_crop_ratio)\n",
    "    crop_height = int(height * crop_ratio)\n",
    "    crop_width = int(width * crop_ratio)\n",
    "\n",
    "    # calculate crop coordinates\n",
    "    y1 = (height - crop_height) // 2\n",
    "    y2 = y1 + crop_height\n",
    "    x1 = (width - crop_width) // 2\n",
    "    x2 = x1 + crop_width\n",
    "\n",
    "    # perform the crop\n",
    "    cropped_image = image[y1:y2, x1:x2]\n",
    "\n",
    "    return cropped_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba5cfd3-a54e-46a9-9a28-435b34faa3ec",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "Another type of common image noise is called salt & pepper noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7b4a1a5-2eaa-451a-bd8c-6ac929127169",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"images/camera.jpg\")\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "prob_mat = rng.uniform(0, 1, size=img.shape[:2])\n",
    "\n",
    "degree_noise = 0.05\n",
    "img_noise = img.copy()\n",
    "\n",
    "# add noise\n",
    "img_noise[prob_mat <= degree_noise / 2, ...] = (0, 0, 0)\n",
    "img_noise[prob_mat >= 1 - (degree_noise / 2), ...] = (255, 255, 255)\n",
    "\n",
    "cv.imshow(\"original\", img)\n",
    "cv.imshow(\"salt & pepper noise\", img_noise)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7bc0500-fee4-4a5f-9f8d-97881a63993e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
